{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a72a26",
   "metadata": {},
   "source": [
    "Projeto Sistemas Inteligentes\n",
    "\n",
    "Grupo\n",
    "    Gustavo Alves de Lima RA: 11103516\n",
    "    Henrique Soares Silva RA: 11071116\n",
    "    Jessica Faria Rodrigues Zeferino RA: 11054416\n",
    "    Lucas Garcia Fracaro RA: 11026316\n",
    "    Marcelo Tranche Junior RA:11201810416\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e8e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/alves/anaconda3/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/alves/.local/lib/python3.8/site-packages (from tensorflow) (1.21.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/alves/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/alves/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/alves/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/alves/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/alves/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/alves/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/alves/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alves/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alves/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/alves/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e2fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 22:55:44.912665: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-01 22:55:44.912702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#importação das bibliotecas necessárias para a construção do modelo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3705d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23705, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        age  ethnicity  gender                        img_name  \\\n",
       "0        1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1        1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2        1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3        1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4        1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "...    ...        ...     ...                             ...   \n",
       "23700   99          0       1  20170120221920654.jpg.chip.jpg   \n",
       "23701   99          1       1  20170120134639935.jpg.chip.jpg   \n",
       "23702   99          2       1  20170110182418864.jpg.chip.jpg   \n",
       "23703   99          2       1  20170117195405372.jpg.chip.jpg   \n",
       "23704   99          0       1  20170110182052119.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "0      129 128 128 126 127 130 133 135 139 142 145 14...  \n",
       "1      164 74 111 168 169 171 175 182 184 188 193 199...  \n",
       "2      67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
       "3      193 197 198 200 199 200 202 203 204 205 208 21...  \n",
       "4      202 205 209 210 209 209 210 211 212 214 218 21...  \n",
       "...                                                  ...  \n",
       "23700  127 100 94 81 77 77 74 99 102 98 128 145 160 1...  \n",
       "23701  23 28 32 35 42 47 68 85 98 103 113 117 130 129...  \n",
       "23702  59 50 37 40 34 19 30 101 156 170 177 184 187 1...  \n",
       "23703  45 108 120 156 206 197 140 180 191 199 204 207...  \n",
       "23704  156 161 160 165 170 173 166 177 183 191 187 18...  \n",
       "\n",
       "[23705 rows x 5 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leitura dos dados e criação do dataset\n",
    "\n",
    "data = pd.read_csv(\"age_gender.csv\")\n",
    "print(data.shape)\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b94980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23705, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        age  ethnicity  gender  \\\n",
       "0        1          2       0   \n",
       "1        1          2       0   \n",
       "2        1          2       0   \n",
       "3        1          2       0   \n",
       "4        1          2       0   \n",
       "...    ...        ...     ...   \n",
       "23700   99          0       1   \n",
       "23701   99          1       1   \n",
       "23702   99          2       1   \n",
       "23703   99          2       1   \n",
       "23704   99          0       1   \n",
       "\n",
       "                                                  pixels  \n",
       "0      129 128 128 126 127 130 133 135 139 142 145 14...  \n",
       "1      164 74 111 168 169 171 175 182 184 188 193 199...  \n",
       "2      67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
       "3      193 197 198 200 199 200 202 203 204 205 208 21...  \n",
       "4      202 205 209 210 209 209 210 211 212 214 218 21...  \n",
       "...                                                  ...  \n",
       "23700  127 100 94 81 77 77 74 99 102 98 128 145 160 1...  \n",
       "23701  23 28 32 35 42 47 68 85 98 103 113 117 130 129...  \n",
       "23702  59 50 37 40 34 19 30 101 156 170 177 184 187 1...  \n",
       "23703  45 108 120 156 206 197 140 180 191 199 204 207...  \n",
       "23704  156 161 160 165 170 173 166 177 183 191 187 18...  \n",
       "\n",
       "[23705 rows x 4 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminando variável que não importa (nome da imagem)\n",
    "\n",
    "data = data.drop('img_name', axis=1)\n",
    "print(data.shape)\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11551e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23705,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separação dos dados para treinamento e teste\n",
    "\n",
    "#coletando somente as informações sobre os pixels\n",
    "data_pixel = data['pixels']\n",
    "data_pixel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74409152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[184, 183, 189, ...,  53,  62,  73],\n",
       "       [184, 184, 182, ..., 140, 142, 145],\n",
       "       [195, 190, 173, ..., 215, 191, 160],\n",
       "       ...,\n",
       "       [239, 239, 238, ..., 197, 204, 229],\n",
       "       [238, 238, 239, ..., 201, 205, 228],\n",
       "       [240, 240, 239, ..., 205, 203, 227]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#montando as dimenções da foto e guardando em forma de vetor\n",
    "\n",
    "data_fotos = []\n",
    "\n",
    "for i in range(data_pixel.shape[0]):\n",
    "    data_fotos.append(np.array(data_pixel[i].split(' '), dtype='int64').reshape(48,48))\n",
    "\n",
    "#uma amostra\n",
    "\n",
    "data_fotos = np.array(data_fotos)\n",
    "\n",
    "data_fotos[np.random.randint(0,100)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1443aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converto variaveis categoricas em flags\n",
    "\n",
    "gender = pd.get_dummies(data['gender']).values\n",
    "ethnicity = pd.get_dummies(data['ethnicity']).values\n",
    "age = data['age'].values\n",
    "#separação entre os dados de treino e teste de 50%\n",
    "\n",
    "#jogar um valor fora para conseguir treinar o modelo\n",
    "\n",
    "\n",
    "#x_train, x_test, y_train_gender, y_test_gender, y_train_ethnicity, y_test_ethnicity, y_train_age, y_test_age = train_test_split(\n",
    "    #data_pixel, gender, ethnicity, data['age'].values,test_size=0.5, random_state=1234)\n",
    "    \n",
    "X_train_ethnicity, X_test_ethnicity, y_train_ethnicity, y_test_ethnicity = train_test_split(data_fotos, ethnicity, test_size= 0.3)\n",
    "X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(data_fotos, gender, test_size= 0.3)\n",
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(data_fotos, age, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c847cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importações para a criação do modelo\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "#rom tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, InputLayer\n",
    "\n",
    "import keras\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373a73d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo r²\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3bd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição do modelo\n",
    "\n",
    "def modelo(num_classes, activation, loss, metric):\n",
    "    modelo = Sequential() \n",
    "    modelo.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "    modelo.add(BatchNormalization())\n",
    "    modelo.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    modelo.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))# padding = \"same\"))\n",
    "    modelo.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(64, activation='relu'))\n",
    "    modelo.add(Dropout(0.5))\n",
    "    modelo.add(Dense(num_classes, activation= activation))\n",
    "    modelo.compile(optimizer='Adam',\n",
    "              loss= loss,\n",
    "              metrics=[metric])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e68c4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(modelo(5,\"softmax\",'categorical_crossentropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0064d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca9af60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 23:15:33.550311: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 305842176 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 1.3341 - accuracy: 0.4928WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 23s 43ms/step - loss: 1.3341 - accuracy: 0.4928 - val_loss: 1.0343 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 1.1383 - accuracy: 0.5444WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 1.1383 - accuracy: 0.5444 - val_loss: 1.0524 - val_accuracy: 0.5775 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 1.0816 - accuracy: 0.5712WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 1.0814 - accuracy: 0.5713 - val_loss: 0.9769 - val_accuracy: 0.6583 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 1.0415 - accuracy: 0.5919WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 1.0415 - accuracy: 0.5919 - val_loss: 0.8725 - val_accuracy: 0.6895 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 1.0074 - accuracy: 0.6036WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 1.0074 - accuracy: 0.6036 - val_loss: 0.8457 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.9863 - accuracy: 0.6134WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.9863 - accuracy: 0.6134 - val_loss: 0.8477 - val_accuracy: 0.6945 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.9887 - accuracy: 0.6055WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.9889 - accuracy: 0.6055 - val_loss: 0.8831 - val_accuracy: 0.7011 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.9528 - accuracy: 0.6198WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 43ms/step - loss: 0.9526 - accuracy: 0.6200 - val_loss: 0.7520 - val_accuracy: 0.7490 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.9392 - accuracy: 0.6223WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.9390 - accuracy: 0.6225 - val_loss: 0.7912 - val_accuracy: 0.7354 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.9216 - accuracy: 0.6303WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.9216 - accuracy: 0.6303 - val_loss: 0.7645 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.6361WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 43ms/step - loss: 0.9140 - accuracy: 0.6361 - val_loss: 0.7733 - val_accuracy: 0.7343 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.9125 - accuracy: 0.6366WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.9125 - accuracy: 0.6366 - val_loss: 0.7626 - val_accuracy: 0.7482 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.8988 - accuracy: 0.6397WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.8988 - accuracy: 0.6397 - val_loss: 0.7582 - val_accuracy: 0.7403 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.8897 - accuracy: 0.6413WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 43ms/step - loss: 0.8897 - accuracy: 0.6413 - val_loss: 0.7527 - val_accuracy: 0.7449 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.8703 - accuracy: 0.6482WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 23s 44ms/step - loss: 0.8703 - accuracy: 0.6482 - val_loss: 0.7947 - val_accuracy: 0.7209 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.8673 - accuracy: 0.6543WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.8675 - accuracy: 0.6542 - val_loss: 0.7858 - val_accuracy: 0.7234 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.6487WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.8705 - accuracy: 0.6487 - val_loss: 0.8313 - val_accuracy: 0.6983 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.8558 - accuracy: 0.6527WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 43ms/step - loss: 0.8558 - accuracy: 0.6527 - val_loss: 0.7329 - val_accuracy: 0.7551 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.8341 - accuracy: 0.6644WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 43ms/step - loss: 0.8337 - accuracy: 0.6646 - val_loss: 0.7613 - val_accuracy: 0.7494 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.8147 - accuracy: 0.6669WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 43ms/step - loss: 0.8152 - accuracy: 0.6669 - val_loss: 0.7372 - val_accuracy: 0.7506 - lr: 0.0010\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - ETA: 0s - loss: 0.8092 - accuracy: 0.6680WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.8092 - accuracy: 0.6680 - val_loss: 0.7590 - val_accuracy: 0.7458 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.7769 - accuracy: 0.6900WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7776 - accuracy: 0.6898 - val_loss: 0.7327 - val_accuracy: 0.7507 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.7680 - accuracy: 0.6947WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7678 - accuracy: 0.6949 - val_loss: 0.7872 - val_accuracy: 0.7388 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.7552 - accuracy: 0.6985WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7557 - accuracy: 0.6983 - val_loss: 0.7461 - val_accuracy: 0.7555 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.7428 - accuracy: 0.7020WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7434 - accuracy: 0.7018 - val_loss: 0.8026 - val_accuracy: 0.7192 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.7348 - accuracy: 0.7045WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7344 - accuracy: 0.7045 - val_loss: 0.7649 - val_accuracy: 0.7532 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.7328 - accuracy: 0.7053WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7339 - accuracy: 0.7049 - val_loss: 0.7502 - val_accuracy: 0.7531 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.7284 - accuracy: 0.7073WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.7284 - accuracy: 0.7073 - val_loss: 0.7590 - val_accuracy: 0.7634 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 23:25:40.771354: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 305842176 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.4808 - accuracy: 0.7745WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 41ms/step - loss: 0.4804 - accuracy: 0.7747 - val_loss: 0.3584 - val_accuracy: 0.8351 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8465WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 0.3391 - accuracy: 0.8462 - val_loss: 0.3073 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.8658WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.3048 - accuracy: 0.8658 - val_loss: 0.2968 - val_accuracy: 0.8645 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.8796WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.2726 - accuracy: 0.8797 - val_loss: 0.2795 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.8807WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.2629 - accuracy: 0.8807 - val_loss: 0.2733 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.8902WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.2454 - accuracy: 0.8903 - val_loss: 0.2634 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.8923WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.2345 - accuracy: 0.8923 - val_loss: 0.2693 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.8995WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.2228 - accuracy: 0.8995 - val_loss: 0.2803 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9038WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.2143 - accuracy: 0.9037 - val_loss: 0.2898 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9088WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 0.2023 - accuracy: 0.9087 - val_loss: 0.2701 - val_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9123WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.1917 - accuracy: 0.9123 - val_loss: 0.2735 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.1823 - accuracy: 0.9168WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.1823 - accuracy: 0.9167 - val_loss: 0.3018 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9194WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.1765 - accuracy: 0.9194 - val_loss: 0.3041 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9239WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.1690 - accuracy: 0.9239 - val_loss: 0.3231 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9249WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.1642 - accuracy: 0.9249 - val_loss: 0.3265 - val_accuracy: 0.8836 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9283WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 0.1548 - accuracy: 0.9283 - val_loss: 0.3118 - val_accuracy: 0.8836 - lr: 0.0010\n",
      "Epoch 1/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 259.6557 - coeff_determination: 0.3026WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 22s 41ms/step - loss: 259.7177 - coeff_determination: 0.3029 - val_loss: 138.5933 - val_coeff_determination: 0.6293 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 182.9830 - coeff_determination: 0.5015WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 182.9387 - coeff_determination: 0.5017 - val_loss: 125.9816 - val_coeff_determination: 0.6659 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 165.2514 - coeff_determination: 0.5467WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 22s 42ms/step - loss: 165.2580 - coeff_determination: 0.5466 - val_loss: 215.3933 - val_coeff_determination: 0.3968 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 157.2994 - coeff_determination: 0.5713WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 21s 41ms/step - loss: 157.3248 - coeff_determination: 0.5712 - val_loss: 144.8432 - val_coeff_determination: 0.5971 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 146.5412 - coeff_determination: 0.5972WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 146.5412 - coeff_determination: 0.5972 - val_loss: 109.9315 - val_coeff_determination: 0.7002 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 143.5100 - coeff_determination: 0.6079WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 143.6185 - coeff_determination: 0.6076 - val_loss: 106.8243 - val_coeff_determination: 0.7121 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 136.5939 - coeff_determination: 0.6254WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 136.5939 - coeff_determination: 0.6254 - val_loss: 101.2177 - val_coeff_determination: 0.7268 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 137.1307 - coeff_determination: 0.6237WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 137.1379 - coeff_determination: 0.6239 - val_loss: 103.9720 - val_coeff_determination: 0.7187 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 131.5858 - coeff_determination: 0.6381WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 131.5315 - coeff_determination: 0.6383 - val_loss: 106.2584 - val_coeff_determination: 0.7100 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 130.9777 - coeff_determination: 0.6375WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 131.0348 - coeff_determination: 0.6377 - val_loss: 131.1370 - val_coeff_determination: 0.6413 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 126.7726 - coeff_determination: 0.6497WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 126.7228 - coeff_determination: 0.6498 - val_loss: 120.7835 - val_coeff_determination: 0.6764 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 122.6009 - coeff_determination: 0.6605WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 122.6009 - coeff_determination: 0.6605 - val_loss: 123.3417 - val_coeff_determination: 0.6565 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "518/518 [==============================] - ETA: 0s - loss: 122.4801 - coeff_determination: 0.6620WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 122.4801 - coeff_determination: 0.6620 - val_loss: 128.8535 - val_coeff_determination: 0.6566 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 120.7490 - coeff_determination: 0.6686WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 120.7029 - coeff_determination: 0.6684 - val_loss: 149.7159 - val_coeff_determination: 0.5793 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 115.5603 - coeff_determination: 0.6848WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 40ms/step - loss: 115.7041 - coeff_determination: 0.6847 - val_loss: 133.6418 - val_coeff_determination: 0.6435 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 119.9005 - coeff_determination: 0.6664WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 120.0359 - coeff_determination: 0.6658 - val_loss: 108.1510 - val_coeff_determination: 0.7084 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "517/518 [============================>.] - ETA: 0s - loss: 116.5030 - coeff_determination: 0.6777-WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,coeff_determination,val_loss,val_coeff_determination,lr\n",
      "518/518 [==============================] - 21s 41ms/step - loss: 116.6179 - coeff_determination: 0.6774 - val_loss: 186.9492 - val_coeff_determination: 0.5030 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#200 gerações para treino com o tamanho de 64 fotos\n",
    "\n",
    "#temos 5 categorias de etinia no dataset\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.001,restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "geracoes = 100\n",
    "tamanho = 32\n",
    "\n",
    "#etnia\n",
    "modelo_ethnicity = modelo(5,\"softmax\",'categorical_crossentropy', 'accuracy')\n",
    "history_ethnicity = modelo_ethnicity.fit(X_train_ethnicity, y_train_ethnicity, batch_size=tamanho,\n",
    "                              epochs = geracoes, validation_data = (X_test_ethnicity,y_test_ethnicity), steps_per_epoch= X_train_ethnicity.shape[0] // tamanho, callbacks= [early_stopping, learning_rate_reduction])\n",
    "\n",
    "#genero\n",
    "\n",
    "modelo_gender = modelo(2,\"softmax\",'categorical_crossentropy', 'accuracy')\n",
    "history_gender = modelo_gender.fit(X_train_gender, y_train_gender, batch_size=tamanho,\n",
    "                              epochs = geracoes, validation_data = (X_test_gender,y_test_gender), steps_per_epoch= X_train_gender.shape[0] // tamanho, callbacks= [early_stopping, learning_rate_reduction])\n",
    "#idade\n",
    "\n",
    "modelo_age = modelo(1,\"relu\",'mean_squared_error', coeff_determination )\n",
    "history_age = modelo_age.fit(X_train_age, y_train_age, batch_size=tamanho,\n",
    "                              epochs = geracoes, validation_data = (X_test_age,y_test_age), steps_per_epoch= X_train_age.shape[0] // tamanho, callbacks= [early_stopping, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9262bcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 08:34:16.924824: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://427ee8f9-e5e4-44b1-9a32-60ffab4056c7/assets\n",
      "INFO:tensorflow:Assets written to: ram://7eb4a2a1-3d08-4e16-bb99-7eca38724a79/assets\n",
      "INFO:tensorflow:Assets written to: ram://e7626a2a-c1fe-4ab0-91d3-5e8a5d98920f/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#salvar o modelo\n",
    "filehandler = open(\"model_ethnicity.obj\",\"wb\")\n",
    "pickle.dump(modelo_ethnicity,filehandler)\n",
    "\n",
    "filehandler = open(\"model_gender.obj\",\"wb\")\n",
    "pickle.dump(modelo_gender,filehandler)\n",
    "\n",
    "filehandler = open(\"model_age.obj\",\"wb\")\n",
    "pickle.dump(modelo_age,filehandler)\n",
    "\n",
    "#load modelo\n",
    "\n",
    "object_file = pickle.load(open(\"model_ethnicity.obj\",'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
